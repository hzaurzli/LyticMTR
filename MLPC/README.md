# MLPC
![MLPC](https://github.com/user-attachments/assets/c4f2b9db-90e3-44f9-9ca2-66c95801b31b)

# Installation

Using conda to create env

```
# By conda
conda env create -f MLPC.yaml

# Activate env
source activate mlpc
```

# How to start
## a.Feature engineering
**1.Property:**

Get your fasta file ready (protein), switch your path
```
Rscript property_feat.R -i protein.fa -o feature_table.txt
## -i input protein fasta! format .fa (.fasta)
## -o output property table! format .txt
```

**2.Sequence and Secondary structure:**

For secondary structure predictions we recommend using the SCRATCH-1D to obtain '.ss8' file

```
python feature_engine.py -f protein.fa -s secondary_structure.ss8 -p property.txt -rf feature_table.txt
## -f protein sequence
## -s ss8 format,secondary structure
## -p property table ('\t')
## -rf feature matrix file (output)
```

## b.Trainer

Training set testing set and validation set are generated by random sampling

```
# For example 'glycosidase'
python random_sample.py -i ./feat_glycosidase.txt -or ./random_sample/feat_glycosidase_1500.txt -oe ./testsets/feat_glycosidase_1500.txt -ov ./valid/feat_glycosidase_1500.txt -kr 1500 -ke 1500 -kv 1500
## -i input feature table (txt,'\t')
## -or output training feature table (after sample, txt,'\t')
## -oe output testing feature table (after sample, txt,'\t')
## -ov output validation feature table (after sample, txt,'\t')
## -kr sample number for training
## -ke sample number for testing
## -kv sample number for validation

# Obtain training sets
cat feat_amidase_1500.txt feat_MES_1500.txt feat_glycosidase_1500.txt feat_other_1500.txt feat_endo-peptidase_827.txt > train_1.txt

# Mlsmote
python mlsmote.py -iX train_1.txt -iy laber_class.txt -o random_sample -n 673
## -iX feature table (txt,'\t')
## -iy laber file (txt, '\t')
## -o output path
## -n number of newly generated sample
```

**Training model:**

```
# Obtain training sets after mlsmote
cat feat_amidase_1500.txt feat_MES_1500.txt feat_glycosidase_1500.txt feat_other_1500.txt X_res.txt > train_2.txt

# Run CNN
python run_CNN.py -iX train_2.txt -iy laber.txt
## -iX feature table (txt,'\t')
## -iy laber file (txt, '\t')

# Run BiGRU
python run_BiGRU.py -iX train_2.txt -iy laber.txt
## -iX feature table (txt,'\t')
## -iy laber file (txt, '\t')
```

## c.Tester

If you want to test model performance, testing below:

```
python tester.py -iX test.txt -iy laber.txt -m model.h5
## -iX feature table for test sets (txt,'\t')
## -iy laber file for test set (txt, '\t')
## -m  model path (.h5)
```

## d.Predictor

If you want to predict new proteins, see below:

```
python predictor.py -iX new_feature.txt -r res.txt -m model.h5
## -iX feature table for new sets (txt,'\t')
## -r  result file (txt,'\t')
## -m  model path (.h5)
```



